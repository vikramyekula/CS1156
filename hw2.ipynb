{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, 2. Hoefding Inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_toss(num_of_tosses=10, num_of_coins=1000):\n",
    "    toss = ['H', 'T']\n",
    "    result = []\n",
    "    #[result.append([toss[j] for j in np.random.randint(2, size=num_of_tosses)])]\n",
    "    for i in range(num_of_coins):\n",
    "        result.append([toss[j] for j in np.random.randint(2, size=num_of_tosses)])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_heads(result, num_of_tosses=10):\n",
    "    v_one = len(np.where(result[0] == 'H')[0]) / num_of_tosses\n",
    "    v_rand = len(np.where(result[np.random.randint(len(result))] == 'H')[0]) / num_of_tosses\n",
    "    freq_head = []\n",
    "    [freq_head.append(len(np.where(result[i] == 'H')[0])) for i in range(len(result))]\n",
    "    v_min = np.min(np.array(freq_head)) / num_of_tosses\n",
    "    return [v_one, v_rand, v_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_12(trails=100000, num_of_tosses=10, num_of_coins=1000):\n",
    "    trails_result = []\n",
    "    [trails_result.append(frequency_of_heads(coin_toss(num_of_tosses, num_of_coins))) for i in range(trails)]\n",
    "    return np.array(trails_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "num_trails = 100000\n",
    "trails = experiment_12(num_trails, 10, 1000)\n",
    "end_time = time.time()\n",
    "means = np.mean(trails, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 100000 trails is 1346.641705751419\n",
      "Average Fraction of Heads for first coin = 0.499783\n",
      "Average Fraction of Heads for random coin = 0.4994979999999959\n",
      "Average Fraction of Heads for the coin with minimum heads% = 0.03758799999997677\n",
      "1. Difference values for E_in - [ 0.037588  0.027588  0.062412  0.462412  0.632412]\n",
      "1. Answer for E_in is b\n"
     ]
    }
   ],
   "source": [
    "print('Time taken for {} trails is {}'.format(num_trails, (end_time - start_time)))\n",
    "print('Average Fraction of Heads for first coin = {}'.format(means[0]))\n",
    "print('Average Fraction of Heads for random coin = {}'.format(means[1]))\n",
    "print('Average Fraction of Heads for the coin with minimum heads% = {}'.format(means[2]))\n",
    "answer_choices = [0, 0.01, 0.1, 0.5, 0.67]\n",
    "answers = ['a', 'b', 'c', 'd', 'e']\n",
    "print('1. Difference values for E_in - {}'.format(np.absolute(np.array(answer_choices) - means[2])))\n",
    "print('1. Answer for E_in is {}'.format(answers[np.argmin(np.absolute(np.array(answer_choices) - means[2]))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    92.,    971.,  16342.,      0.,  20308.,  45101.,  11752.,\n",
       "             0.,   4321.,   1113.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEkqygCQpKIMAEkqygCQpKL+HyL+ePat/A1rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25fb17c3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.distplot(trails[:, 0])\n",
    "plt.hist(trails[:, 0])\n",
    "#for i in range(10+1):\n",
    "#    print('For value {}, # of trails {}'.format(i, len(np.where(trails[:, 2]*10 == i)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   121.,    956.,  16104.,      0.,  20694.,  45007.,  11706.,\n",
       "             0.,   4374.,   1038.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUlH/DwgRfEUefHmUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25fb36eb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trails[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.24130000e+04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.75860000e+04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([ 0.  ,  0.02,  0.04,  0.06,  0.08,  0.1 ,  0.12,  0.14,  0.16,\n",
       "         0.18,  0.2 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr3YEddJNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25fb1c446a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trails[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5, 6, 7 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_line():\n",
    "    x1, x2 = np.random.uniform(-1., 1., size=(2,2))\n",
    "    slope = (x2[1] - x1[1]) / (x2[0] - x1[0])\n",
    "    intercept = x2[1] - slope * x2[0]\n",
    "    return np.array([intercept, slope, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    data = np.random.uniform(-1., 1., size=(N, 2))\n",
    "    data_set = np.column_stack((np.ones(N), data))\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(data, W):\n",
    "    labels = np.sign(data.dot(W))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron(data, correct_labels, W):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        trained_labels = prediction(data, W)\n",
    "        miss_indices = np.where(trained_labels != correct_labels)\n",
    "        if (len(miss_indices[0]) == 0):\n",
    "            break\n",
    "        index = np.random.choice(miss_indices[0])\n",
    "        W = W + correct_labels[index] * data[index]\n",
    "        counter += 1\n",
    "    return (W, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(training_set, correct_labels):\n",
    "    # w = X.T X inverse X.T y\n",
    "    W = np.dot(np.dot(inv(np.dot(training_set.transpose(), training_set)), training_set.transpose()), correct_labels)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_567(trails = 1000, N_in = 100, N_out = 1000, N_pla=10):\n",
    "    iterations = []\n",
    "    iter_prob_ein = []\n",
    "    iter_prob_eout = []\n",
    "    for t in range(trails):\n",
    "        f = target_line()\n",
    "        training_set = generate_data(N_in)\n",
    "        correct_labels = prediction(training_set, f)\n",
    "        # Linear Regression and training set error E_in\n",
    "        W_lr = linear_regression(training_set, correct_labels)\n",
    "        predicted_labels = prediction(training_set, W_lr)\n",
    "        g_not_f = (correct_labels != predicted_labels)\n",
    "        p = len([i for i in g_not_f if i == True]) / N_in\n",
    "        iter_prob_ein.append(p)\n",
    "        \n",
    "        # Test set error rate - E_out\n",
    "        test_set = generate_data(N_out)\n",
    "        true_labels = prediction(test_set, f)\n",
    "        predicted_labels = prediction(test_set, W_lr)\n",
    "        \n",
    "        g_not_f = (true_labels != predicted_labels)\n",
    "        p = len([i for i in g_not_f if i == True]) / N_out\n",
    "        iter_prob_eout.append(p)\n",
    "        \n",
    "        # PLA convergence for the weights from linear regression\n",
    "        training_set = generate_data(N_pla)\n",
    "        correct_labels = prediction(training_set, f)\n",
    "        W_pla, counter = perceptron(training_set, correct_labels, W_lr)\n",
    "        iterations.append(counter)\n",
    "        \n",
    "        \n",
    "    return np.mean(iter_prob_ein), np.mean(iter_prob_eout), np.mean(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiment for LR\n",
    "e_in, e_out, pla_iterations = experiment_567()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-in is 0.038810000000000004. E-out is 0.048039000000000005\n",
      "5. Difference values for E_in - [ 0.03881  0.03781  0.02881  0.06119  0.46119]\n",
      "5. Answer for E_in is c\n",
      "6. Difference values for E_out - [ 0.048039  0.047039  0.038039  0.051961  0.451961]\n",
      "6. Answer for E_out is c\n",
      "7. Difference values for PLA Iterations - [  3.66800000e+00   1.03320000e+01   2.95332000e+02   4.99533200e+03\n",
      "   9.99533200e+03]\n",
      "7. Answer for PLA Iterations is a\n"
     ]
    }
   ],
   "source": [
    "print('E-in is {}. E-out is {}'.format(e_in, e_out))\n",
    "answer_choices = [0, 0.001, 0.01, 0.1, 0.5]\n",
    "answers = ['a', 'b', 'c', 'd', 'e']\n",
    "print('5. Difference values for E_in - {}'.format(np.absolute(np.array(answer_choices) - e_in)))\n",
    "print('5. Answer for E_in is {}'.format(answers[np.argmin(np.absolute(np.array(answer_choices) - e_in))]))\n",
    "print('6. Difference values for E_out - {}'.format(np.absolute(np.array(answer_choices) - e_out)))\n",
    "print('6. Answer for E_out is {}'.format(answers[np.argmin(np.absolute(np.array(answer_choices) - e_out))]))\n",
    "answers_7 = [1, 15, 300, 5000, 10000]\n",
    "print('7. Difference values for PLA Iterations - {}'.format(np.absolute(np.array(answers_7) - pla_iterations)))\n",
    "print('7. Answer for PLA Iterations is {}'.format(answers[np.argmin(np.absolute(np.array(answers_7) - pla_iterations))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8, 9, 10 Nonlinear Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_noise(data, percentage):\n",
    "    N = len(data)\n",
    "    N_noise = int(N * percentage)\n",
    "    random_indices = np.random.randint(N, size=N_noise)\n",
    "    #print('Random Indices: {}'.format(random_indices))\n",
    "    for i in range(len(random_indices)):\n",
    "        if data[random_indices[i]] == 1:\n",
    "            data[random_indices[i]] = -1\n",
    "        else: \n",
    "            data[random_indices[i]] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_lr(data):\n",
    "    labels = np.sign(np.add(-0.6, np.sum(np.square(data), axis=1)))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_8910(trails = 1000, N_in = 1000, N_out = 1000, N_pla=10):\n",
    "    iterations = []\n",
    "    iter_prob_ein = []\n",
    "    iter_w_t = []\n",
    "    iter_prob_eout = []\n",
    "    for t in range(trails):\n",
    "        f = target_line()\n",
    "        training_set = generate_data(N_in)\n",
    "        correct_labels = prediction_lr(training_set[:, 1:])\n",
    "        correct_labels = simulate_noise(correct_labels, 10/100)\n",
    "        # Linear Regression and training set error E_in\n",
    "        W_lr = linear_regression(training_set, correct_labels)\n",
    "        predicted_labels = prediction(training_set, W_lr)\n",
    "        g_not_f = (correct_labels != predicted_labels)\n",
    "        p = len([i for i in g_not_f if i == True]) / N_in\n",
    "        iter_prob_ein.append(p)\n",
    "        \n",
    "        # Non-linear transformation\n",
    "        # (1; x1; x2; x1*x2; x1^2; x2^2)\n",
    "        transformed_training_set = np.column_stack((training_set, \n",
    "                                                    np.multiply(training_set[:, 1], training_set[:, 2]),\n",
    "                                                   np.square(training_set[:, 1]),\n",
    "                                                   np.square(training_set[:, 2])))\n",
    "        W_tlr = linear_regression(transformed_training_set, correct_labels)\n",
    "        iter_w_t.append(W_tlr)\n",
    "        \n",
    "        # Test set error rate - E_out\n",
    "        test_set = generate_data(N_out)\n",
    "        transformed_test_set = np.column_stack((test_set, \n",
    "                                                    np.multiply(test_set[:, 1], test_set[:, 2]),\n",
    "                                                   np.square(test_set[:, 1]),\n",
    "                                                   np.square(test_set[:, 2])))\n",
    "        true_labels = prediction_lr(test_set[:, 1:])\n",
    "        true_labels = simulate_noise(true_labels, 10/100)\n",
    "        predicted_labels = prediction(transformed_test_set, W_tlr)\n",
    "        \n",
    "        g_not_f = (true_labels != predicted_labels)\n",
    "        p = len([i for i in g_not_f if i == True]) / N_out\n",
    "        iter_prob_eout.append(p)\n",
    "        \n",
    "        \n",
    "    return np.mean(iter_prob_ein), np.mean(iter_w_t, axis=0), np.mean(iter_prob_eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_in, w_t, e_out = experiment_8910(1000, 1000, 1000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_in:0.506177\n",
      "w_t:[-1.0149777  -0.00037868 -0.00224469  0.00151316  1.59109194  1.5951449 ]\n",
      "e_out:0.117231\n",
      "8. Difference values for E_in - [ 0.506177  0.406177  0.206177  0.006177  0.293823]\n",
      "8. Answer for E_in is d\n",
      "9. W vector for transformed X - [-1.0149777  -0.00037868 -0.00224469  0.00151316  1.59109194  1.5951449 ]\n",
      "10. Difference values for e_out - [ 0.117231  0.017231  0.182769  0.382769  0.682769]\n",
      "10. Answer for e_out is b\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print('e_in:{}\\nw_t:{}\\ne_out:{}'.format(e_in, w_t, e_out))\n",
    "\n",
    "answers = ['a', 'b', 'c', 'd', 'e']\n",
    "answer_8 = [0, 0.1, 0.3, 0.5, 0.8]\n",
    "print('8. Difference values for E_in - {}'.format(np.absolute(np.array(answer_8) - e_in)))\n",
    "print('8. Answer for E_in is {}'.format(answers[np.argmin(np.absolute(np.array(answer_8) - e_in))]))\n",
    "answers_9 = [\n",
    "    [-1, -0.05, 0.08, 0.13, 1.50, 1.50],\n",
    "    [-1, -0.05, 0.08, 0.13, 1.50, 15.0],\n",
    "    [-1, -0.05, 0.08, 0.13, 15.0, 1.50],\n",
    "    [-1, -1.50, 0.08, 0.13, 0.05, 0.05],\n",
    "    [-1, -0.05, 0.08, 1.50, 0.15, 0.15]\n",
    "]\n",
    "print('9. W vector for transformed X - {}'.format(w_t))\n",
    "#print('9. Answer for E_out is {}'.format(answers[np.argmin(np.absolute(np.array(answers_9) - e_out))]))\n",
    "answer_10 = [0, 0.1, 0.3, 0.5, 0.8]\n",
    "print('10. Difference values for e_out - {}'.format(np.absolute(np.array(answer_10) - e_out)))\n",
    "print('10. Answer for e_out is {}'.format(answers[np.argmin(np.absolute(np.array(answer_10) - e_out))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
